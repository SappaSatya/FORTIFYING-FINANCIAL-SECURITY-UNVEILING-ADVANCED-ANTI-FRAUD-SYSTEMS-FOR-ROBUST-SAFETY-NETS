import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
np.random.seed(2)
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, precision_recall_curve, roc_curve, auc, average_precision_score 



data=pd.read_csv('creditcard.csv')



data



data.head()



data.tail()



data.info()



data.shape



count_classes = pd.value_counts(data['Class'], sort = True) 
count_classes.plot(kind = 'bar', rot=0) 
plt.title ("Transaction Class Distribution") 
plt.xticks (range (2)) 
plt.xlabel("Class") 
plt.ylabel("Frequency") 



fraud = data[data['Class'] == 1]
normal = data[data['Class'] == 0]



print(fraud.shape, normal.shape)



f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)
f.suptitle('Amount per transaction by class')

bins = 50

ax1.hist(fraud['Amount'], bins=bins)
ax1.set_title('Fraud')

ax2.hist(normal['Amount'], bins=bins)
ax2.set_title('Normal')

plt.xlabel('Amount ($)')
plt.ylabel('Number of Transactions')
plt.xlim((0, 20000))
plt.yscale('log')



plt.show()



data.isnull().values.any()



fraud.Amount.describe()



normal.Amount.describe()



normal_sample=normal.sample(n=492)



new_dataset = pd.concat([normal_sample, fraud], axis=0)



new_dataset.head()



new_dataset.tail() 



new_dataset.groupby('Class').mean() 



X = new_dataset. drop (columns='Class', axis=1) 



Y = new_dataset['Class']



from sklearn. model_selection import train_test_split 
X = data.iloc[:,:30]
Y = data.iloc[:,30]
print (X.shape)
print (Y.shape) 



X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size=0.25, random_state=2) 
print (X_train.shape) 
print (X_test.shape) 
print (Y_train.shape) 
print (Y_test.shape) 
 


from sklearn import ensemble 
ada = ensemble.AdaBoostClassifier() 
ada.fit(X_train,Y_train)
ada_pred = ada.predict(X_test) 
print("Training Score:%f"%ada.score(X_train,Y_train))
print("Testing Score:%f"%ada.score(X_test,Y_test))



from sklearn.metrics import accuracy_score, classification_report,confusion_matrix 
print (accuracy_score (Y_test, ada_pred)) 
print(classification_report(Y_test,ada_pred)) 
print(confusion_matrix(Y_test,ada_pred)) 




from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc.fit(X_train,Y_train) 
rfc_pred = rfc.predict(X_test) 
print("Training Score: %f"%rfc.score(X_train, Y_train)) 
print("Testing Score: %f"%rfc.score(X_test, Y_test)) 




from sklearn.metrics import accuracy_score, classification_report,confusion_matrix 
print (accuracy_score (Y_test,rfc_pred)) 
print(classification_report(Y_test,rfc_pred)) 
print(confusion_matrix(Y_test,rfc_pred)) 



from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
_
# Counting the number of fraud cases in the test set
n_outliers = len(fraud)

# Counting the number of prediction errors
errors = (rfc_pred != Y_test).sum()

print("The model used is Random Forest classifier")

# Accuracy score
acc = accuracy_score(Y_test, rfc_pred)
print("The accuracy is {}".format(acc))

# Precision score
prec = precision_score(Y_test, rfc_pred)
print("The precision is {}".format(prec))

# Recall score
rec = recall_score(Y_test, rfc_pred)
print("The recall is {}".format(rec))

# F1-score
f1 = f1_score(Y_test, rfc_pred)
print("The F1-Score is {}".format(f1))

# Confusion matrix
LABELS = ['Normal', 'Fraud']
conf_matrix = confusion_matrix(Y_test, rfc_pred)
plt.figure(figsize=(9, 9))
sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d")
plt.title("Confusion matrix")
plt.ylabel('True class')
plt.xlabel('Predicted class')
plt.show()

# Classification report
print(classification_report(Y_test, rfc_pred))

# ROC Curve and AUC
false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, rfc_pred)
roc_auc_rf = roc_auc_score(Y_test, rfc_pred)
print("ROC AUC:", roc_auc_rf)

















